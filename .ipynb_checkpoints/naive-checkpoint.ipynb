{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83435])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "Y_actual = pd.get_dummies(test.sentiment).positive.values\n",
    "Y_pred = np.loadtxt(\"out.txt\")\n",
    "np.sum(Y_actual==Y_pred)/Y_actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"traindata.csv\")\n",
    "test_data = pd.read_csv(\"testdata.csv\")\n",
    "train_data_length = train_data.shape[0]\n",
    "X = pd.concat([train_data.review,test_data.review],axis=0).reset_index().review\n",
    "# X = train_data.review\n",
    "Y_train = pd.get_dummies(train_data.sentiment).positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X):\n",
    "    X = X.str.lower()\n",
    "    X = X.str.replace(r'.',' ')\n",
    "    X = X.str.replace('[^a-zA-Z ]','')\n",
    "    X = X.str.replace(r'\\s+', ' ')\n",
    "#     X = X.str.replace(r'\\W*\\b\\w{1,2}\\b','')\n",
    "    X = X.str.replace(r'([a-z])\\1+', r'\\1')\n",
    "#     X = X.str.replace(r'\\s+[a-zA-Z]\\s+', r'\\1')\n",
    "#     X = X.str.replace(r'([ ])\\1+', r'\\1')\n",
    "    X = X.str.split()\n",
    "    stopwords_set = stopwords.words('english')\n",
    "    stemmer = PorterStemmer()\n",
    "    for i,row in enumerate(X):\n",
    "        print(i,end='\\r',flush=True)\n",
    "        a = []\n",
    "        for word in row:\n",
    "            if word not in stopwords_set:\n",
    "                a.append(word)\n",
    "        X[i] = a\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\r"
     ]
    }
   ],
   "source": [
    "X = preprocess(X[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_keys(X):\n",
    "    words = []\n",
    "    for row in X:\n",
    "        words.extend(row)\n",
    "    return sorted(list(set(words)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4692\n"
     ]
    }
   ],
   "source": [
    "unique_words = get_unique_keys(X[:train_data_length])\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"the\" in set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = pd.DataFrame(np.zeros(len(unique_words)*2).reshape(2,len(unique_words)),columns=unique_words)\n",
    "for i,row in enumerate(X[:train_data_length]):\n",
    "    print(i,end=\"\\r\",flush=True)\n",
    "    sum_df.iloc[Y_train[i],:][list(set(row.split()))]+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_all = get_unique_keys(X)\n",
    "unknown_words = list(set(unique_words_all)-set(unique_words))\n",
    "df2 = pd.DataFrame(np.zeros(len(unknown_words)*2).reshape(2,len(unknown_words)),columns=unknown_words)\n",
    "sum_df = pd.concat([sum_df,df2],axis=1)+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_positive = np.sum(Y_train==1)\n",
    "class_negative = np.sum(Y_train==0)\n",
    "print(class_negative,class_positive)\n",
    "sum_df.iloc[0,:] = np.log(sum_df.iloc[0,:]/(class_negative+1))\n",
    "sum_df.iloc[1,:] = np.log(sum_df.iloc[1,:]/(class_positive+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = []\n",
    "for i,row in enumerate(X[train_data_length:]):\n",
    "    print(i,end=\"\\r\",flush=True)\n",
    "    words = list(set(row.split()))\n",
    "    class_0 = np.log(class_negative/(class_positive+class_negative))+sum_df.iloc[0,:][words].sum()\n",
    "    class_1 = np.log(class_positive/(class_positive+class_negative))+sum_df.iloc[1,:][words].sum()\n",
    "    if(class_0<class_1):\n",
    "        Y_pred.append(1)\n",
    "    else:\n",
    "        Y_pred.append(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
